---
title: "Mini Data Analysis: Report 2"
author: "Harsh Sharma"
date: "21/10/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
This report continues the exploratory data analysis performed in Report1 on the 'cancer_dataset' chosen from the `datateacher` package. Incremental effort will be placed in exploring in more detail the dataset in a fashion that will lead to geenrating insights to answer the research questions.

## Set-up
First we need to load the following two packages:

```{r, message=FALSE}
# Installing packages if missing, required only once
# install.packages("devtools")
# devtools::install_github("UBC-MDS/datateachr")

library(datateachr)
library(tidyverse)
```

## Task1: Processing and Summarizing Data

```{r, include=FALSE, message=FALSE}
# Supporting in-line code below
dim <- dim(cancer_sample)
class <- class(cancer_sample)
```

From earlier analysis we know the cancer_dataset has the following high level characteristics:

  - Shape is: `r dim`
  
  - Data class is: `r class`
  
### Task 1.1: Research Questions

Following are the research questions formulated in Report1:

1. **Can a binary (malignant or benign) classification model be generated the given variables and dataset?**

2.  **Is data distribution/characteristics comparable between the benign and malignant classes?**

3.  **What variable(s) can be used to model the response?**
Which next leads us to finding the optimized set of variables having the highest model performance. This inherently involves analyzing the three associated columns for the same parameter (example: radius\_mean, radius\_se, radius\_worst) in order to minimize redundancy.

4.  **Identifying what variable(s) contributes to the highest model sensitivity**.
In this problem setting it is better to have a false positive than a false negative.

*PS: Research question 4 has been replaced in the following section due to better alignment with this report's instruction requirement and also the course scope.*

### Task 1.2: In-depth EDA
In this section, at least one summarizing and one graphing task is attempted per research question.

#### Question1 - Generating binary classification model
(Pt 1) Computing the summary statistic of numeric variable 'radius_mean' across the categorical variable 'diagnosis':

```{r}
# First grouping by diagnosis
# Using dyplr::unite() to output range as asked in question

cancer_sample %>%
  group_by(diagnosis) %>%
  summarize(min_value=min(radius_mean), max_value=max(radius_mean), mean=mean(radius_mean,na.rm=TRUE),median=median(radius_mean), sd=sd(radius_mean)) %>%
  unite(range, min_value, max_value, sep="-")
```
(Pt 5) Graphing mean_radius with at least two geom layers:
```{r}
# Using classic theme to maximize pixel-info ratio per best practices 

cancer_sample %>%
  ggplot(aes(diagnosis, radius_mean))+
  geom_boxplot(width=0.2)+
  geom_jitter(alpha=0.1, width=0.2)+
  theme_classic()
```

The above results clearly indicate discernible difference in variable 'radius_mean' across benign and malignant diagnosis. This is strong indicator that binary classification is possible.

*Note: Classification model will be generated as part of Report3*

#### Question2 - Comparing benign and malignant data distribution
(Pt 2) Computing the number of observations for categorical variable 'diagnosis':

```{r}
# Without using table() as the output is not data frame

cancer_sample %>%
  group_by(diagnosis) %>%
  tally()
```

Plotting graph of choice, to examine is there is class imbalance:

```{r}
cancer_sample %>%
  ggplot(aes(x=factor(1), fill=diagnosis))+
  geom_bar()+
  coord_polar(theta="y")+
  scale_fill_grey()+
  theme_minimal()+
  theme(axis.title.y = element_blank())
```

(Pt 6) The above graph is appropriate for the research question2. However, an additional graph is plotted below since the instructions require logarithmic axis scale. Logarithmic scale is appropriate when order of magnitude difference is present between values, thus we select variable 'cancavity_mean' which has the highest order of magnitude present; ~600x.

```{r, message=FALSE}
cancer_sample %>%
  arrange(radius_mean) %>%
  ggplot(aes(x=radius_mean, y=concavity_mean))+
  geom_point(aes(color=diagnosis), alpha=0.2)+
  theme_classic()+
  scale_y_continuous("Concavity (mean)", trans="log10", labels = scales::label_scientific())+
  annotation_logticks(sides = "l")
```

The above graph-being not a straight line-and having fairly distinct regions for diagnosis class, delineates valuable insight that radius_mean and concavity_mean do not have high co-llinearity. Thus add variance to model which can benefit from multivariate analysis.

#### Question3 - Variable relationship w.r.t. response
(Pt 3) For effective classification, We will need to compute how other variables are correlated to the response as well. First, we will continue with above variable 'concavity_mean' as an example to demonstrate and fulfill report instructions. This numeric variable has a wide range and is a good candidate for categorization into buckets. Then in next report, we will summarize for all variables.

```{r}
# Adding column for categorization of 'concavity_mean' into 4 buckets

(cancer_categ <- cancer_sample %>%
  mutate(concavity_mean_level = case_when(concavity_mean<0.04 ~ "Low",
                                         concavity_mean<0.08 ~ "Normal",
                                         concavity_mean<0.12 ~ "High",
                                         TRUE ~ "Very High")))
```

Re-plotting using categorized variable 'concavity_mean_levels':

```{r, message=FALSE}
# Using factors for visual appeal by having ascending order in bar proportion

cancer_categ %>%
  mutate(concavity_mean_level= factor(concavity_mean_level, levels = c("Low","Normal","High","Very High"))) %>%
  ggplot(aes(x = concavity_mean_level, fill=diagnosis))+
  geom_bar(position = "fill")+
  labs(y="Proportion")+
  theme_classic()
```

(Pt 8) We will continue to explore the independent variable relationship with response. Now using histograms, with different bin sizes, for another variable 'concave_points_mean':

```{r}
#Bin size count is 20

cancer_sample %>%
  ggplot(aes(x = concave_points_mean, color=diagnosis))+
  geom_histogram(fill="white", bins = 20)+
  theme_classic()
```  
```{r}
#Bin size count is 30

cancer_sample %>%
  ggplot(aes(x = concave_points_mean, color=diagnosis))+
  geom_histogram(fill="white", bins = 30)+
  theme_classic()
```  

```{r}
#Bin size count is 60

cancer_sample %>%
  ggplot(aes(x = concave_points_mean, color=diagnosis))+
  geom_histogram(fill="white", bins = 60)+
  theme_classic()
```  

Thus we can see that even though there is overlap between the two classes, there is still considerable separation that variable 'concave_points_mean' provides for bifurcation.

Additionally, bins=60 is the best as it is more detailed and doesn't overly smooth the multimodal peaks in data, which is the case with bins=20. Bins=30 is also similar in smoothness to bins=60, however lacks some details in the intersecting region. 

#### Question4 - Relationship among closely related variables
(Pt 1) As mentioned above, this question has been updated since report1, and we will examine the relationship across the three closely related variables such as: 'radius_mean', 'radius_se', and 'radius_worst'. The intention is to evaluate if there is high collinearity which can assit in feature selection in report 3.

*Note: (Pt 4) is not much applicable to this dataset, therefore repeating (pt 1) for this excercise:*

As in the above case with 'radius_mean', we first use summary statistics to check if 'radius_se' and 'radius_worst' are relevant independent variables:

```{r}
# Analyzing variable 'radius_se'

cancer_sample %>%
  group_by(diagnosis) %>%
  summarize(min_value=min(radius_se), max_value=max(radius_se), mean=mean(radius_se,na.rm=TRUE),median=median(radius_se), sd=sd(radius_se)) %>%
  unite(range, min_value, max_value, sep="-")
```

```{r}
# Analyzing variable 'radius_worst'

cancer_sample %>%
  group_by(diagnosis) %>%
  summarize(min_value=min(radius_worst), max_value=max(radius_worst), mean=mean(radius_worst,na.rm=TRUE),median=median(radius_worst), sd=sd(radius_worst)) %>%
  unite(range, min_value, max_value, sep="-")
```

We observe good distinction for mean and median values across the diagnostic classes, and thus proceed to plot (Pt 7) the density graphs and use alpha transparency to see the distribution intersections:

```{r}
# For variable 'radius_mean'

cancer_sample %>%
  ggplot(aes(radius_mean))+
  geom_density(aes(fill=diagnosis, alpha=0.3))+
  theme_minimal()
```

```{r}
# For variable 'radius_se'

cancer_sample %>%
  ggplot(aes(radius_se))+
  geom_density(aes(fill=diagnosis, alpha=0.3))+
  theme_minimal()
```

```{r}
# For variable 'radius_worst'

cancer_sample %>%
  ggplot(aes(radius_worst))+
  geom_density(aes(fill=diagnosis, alpha=0.3))+
  theme_minimal()
```

Since 'radius_worst' and 'radius_mean' seem to outperform 'radius_se', we now proceed to check the correlation between them and drop 'radius_se'.

```{r}
cancer_sample %>%
  ggplot(aes(x=radius_mean, y=radius_worst))+
  geom_point(size=0.7, alpha=0.1)+
  geom_smooth()
```

Visually, We can see high degree of correlation at the lower range, with standard error increasing as the range increases. Since there is variance, it is recommended to carry both these variables forward for further analysis in report 3, in consideration of including in the model features.

### Task 1.3: Learning

In summary, I have systematically examined:

- The dataset at a high level (noting there are no missing values).
- The various variables present and the possibility for them to act as features
- The relationship between various independent variables that indicate a good performing model is possible

I am now certain of the research questions (1 question was updated). Most interesting result was obtained by comparing the two classification groups; which highlighted linear relationships within the group but one that differed in rate of change compared intra-group.

**Next steps:**

- Repeated some of the above steps for other variables and summarize outcomes quantitatively
- Use statistical model and set parameters using the outcomes from above step to answer the central research question1 (binary classification)


## Task 2: Tidy Your Data
This section focus on reshaping data using the `tidyr` package in order to simplify computation.

### Task 2.1: Sate of my dataset
My entire dataset (cancer_sample) was by default present in tidy form for my research questions. This is because:

- Each row was an observation (incl. the response variable malignant/benign on individual row)
- All columns represented variables
- Each cell was (a particular) value

### Task 2.2: Reshaping my dataset

I will make my dataset untidy (for my research questions) by making the tibble longer. For every parameter (such as radius, area, etc.) I will combine the three related cols '_mean',  '_se' and '_worst' into one column. Thus, for This will result in 12 cols from 32 cols originally.

```{r}
(cancer_long <- cancer_sample %>%
   pivot_longer(cols     = c(-ID, -diagnosis), 
               names_to  = "feature",
               values_to = "numerical_value"))
```
Now tidying the data back again:

```{r}
(cancer_sample <- cancer_long %>%
   pivot_wider(id_cols     = c(ID, diagnosis), 
               names_from  = "feature",
               values_from = "numerical_value"))
```


### Task 2.3: Further selection of research question and data

Based on the above exercise and more in-depth knowledge about my dataset now, I further select the following two questions:

1. **Can a binary (malignant or benign) classification model be generated with the given variables and dataset size?**

In report 3, additional thought needs to be put in terms of precision-recall, so performance evaluation is more robust given false positive is better than false negative in this situation.

I have selected this as the primary question because it is the culminating exercise that can provide the most utility from analysing this data.

2. **What variable(s) can be used to model the response?**

I have selected this as the second question because it is a requisite pre-cursor to the primary question. Moreover, the model performance will be heavily dictated by the set of features selected.

The other two questions were less important to further investigate as they will already be intrinsically included in the model selection, training, and tuning.

**Data set:**
As discussed above, I need to drop all of the ten '_se' cols:

```{r}
(cancer_final <- cancer_sample %>%
  select(-radius_se, -texture_se, -perimeter_se, -area_se, -smoothness_se, -compactness_se, -concavity_se, -concave_points_se, -symmetry_se, -fractal_dimension_se) %>%
  arrange(diagnosis) %>%  # Arranging for better organization
  select(-ID) %>%   # Removing original ID column as number is non-consistent format
  mutate(ID = row_number()) %>%  # Adding consistent ID column
  select(ID, everything()))      # Moveing ID column as first col
```

My dataset is well formed and tidy, and does not have any missing values; hence does not require any further manipulation to be used on report3. However, to meet the instruction requirements, I hypothetically manipulate data below to showcase familiarity using other functions, as asked: 

```{r}
(cancer_final%>%
  filter(diagnosis=="M", radius_mean > 20)) # Selecting only observations associated to 'malignant' diagnosis class with radius_mean greater than 20
```