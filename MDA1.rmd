---
title: "Mini Data Analysis: Report 1"
author: "Harsh Sharma"
date: "09/10/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview
This report includes the exploratory data analysis performed on a dataset chosen from the `datateacher` package. Incremental effort will be placed in familiarizing with different data sets to finally choose one, and four research questions will formulated around it.

## Set-up
First we need to load the following two packages:

```{r, message=FALSE}
# Installing packages if missing, required only once
# install.packages("devtools")
# devtools::install_github("UBC-MDS/datateachr")

library(datateachr)
library(tidyverse)
```

The `datateachr` is comprised of the 7 semi-tidy datasets:

> 1. apt_buildings: Acquired courtesy of The City of Toronto’s Open Data Portal. It currently has 3455 rows and 37 columns.

> 2. building_permits: Acquired courtesy of The City of Vancouver’s Open Data Portal. It currently has 20680 rows and 14 columns.

> 3. cancer_sample: Acquired courtesy of UCI Machine Learning Repository. It currently has 569 rows and 32 columns.

> 4. flow_sample: Acquired courtesy of The Government of Canada’s Historical Hydrometric Database. It currently has 218 rows and 7 columns.

> 5. parking_meters: Acquired courtesy of The City of Vancouver’s Open Data Portal. It currently has 10032 rows and 22 columns.

> 6. steam_games: Acquire d courtesy of Kaggle. It currently has 40833 rows and 21 columns.

> 7. vancouver_trees: Acquired courtesy of The City of Vancouver’s Open Data Portal. It currently has 146611 rows and 20 columns.

## Task 1.1: Priliminary Dataset Selection

Based on the descriptions, I narrow down my intial choices to the following:

1. *building_permits:* working for a regulatory agency, I have prior experience working in compliance of permits and licenses.

2. *cancer_sample:* I am interested to pursue my research in a field related to algorithms employed in healthcare digital images so this seems very meaningful and applicable

3. *parking_meters:* having worked for Translink, this may be an interesting dataset to probe into parking trends and by extension into travel behavior

4. *vancouver_trees:* interesting dataset that may be leverage-able to assess the effects of climate change and/or rate of planting by the city

## Task 1.2: Introductory Dataset Exploration
In this section, we will individually perform introductory exploration into the four chosen datasets using dyplr to find the associated data attributes. This will enhance the understanding about the information contained within each dataset and enable a more informed decision.

#### Building Permits

```{r}
# Checking the object type of data frame 
class(building_permits)
```

```{r}
# Provides a glimpse into the data, showing:
# Dataframe dimensions, columns, and data types 
glimpse(building_permits)
```
```{r}
# Function to provides result summaries
# Very Helpful for nominal and ordinal data
summary(building_permits)
```
```{r}
# Summarizing permit count by year
building_permits %>% 
  group_by(year) %>%
  summarise(n=n())
```
```{r}
# Finding the different permit types
distinct(building_permits, type_of_work)
```
**Notable Observation:** There are 52 missing numerical values.

#### Cancer Sample

```{r}
# Checking the object type of data frame 
class(cancer_sample)
```

```{r}
# Provides a glimpse into the data, showing:
# Dataframe dimensions, columns, and data types 
glimpse(cancer_sample)
```
```{r}
# Function to provides result summaries
# Very Helpful for nominal and ordinal data
summary(cancer_sample)
```
```{r}
# Finding the types of diagnosis
distinct(cancer_sample, diagnosis)
```
```{r}
# Checking the difference in mean radius between two diagnosis types 
cancer_sample %>% 
  group_by(diagnosis) %>%
  summarize(meanRadius=mean(radius_mean))
```

**Notable Observation:** There is discernable difference between mean radius of begnin and malignant tumor - and this variable can be used in classifying. Since we have only two types of values for diagnosis these will act as factors

#### Parking Meters

```{r}
# Checking the object type of data frame 
class(parking_meters)
```

```{r}
# Provides a glimpse into the data, showing:
# Dataframe dimensions, columns, and data types 
glimpse(parking_meters)
```
```{r}
# Function to provides result summaries
# Very Helpful for nominal and ordinal data
summary(parking_meters)
```

```{r}
# List of different meter heads
distinct(parking_meters, meter_head)
```
```{r}
# Alphabetically arranged list of meter counts by location area 
parking_meters %>% 
  group_by(geo_local_area) %>%
  arrange(geo_local_area) %>%
  summarize(n=n())
```

#### Vancouver Trees

```{r}
# Checking the object type of data frame 
class(vancouver_trees)
```

```{r}
# Provides a glimpse into the data, showing:
# Dataframe dimensions, columns, and data types 
glimpse(vancouver_trees)
```
```{r}
# Function to provides result summaries
# Very Helpful for nominal and ordinal data
summary(vancouver_trees)
```
```{r}
# List of different street sides where trees are present
distinct(vancouver_trees, street_side_name)
```
```{r}
# Checking the difference in mean diameter between different genus tree types 
vancouver_trees %>% 
  group_by(genus_name) %>%
  summarize(meanDiameter=mean(diameter, na.rm=TRUE))
```
```{r}
# Determining distinct genus-specie pairs
distinct(vancouver_trees, genus_name, species_name)
```

**Notable Observation:** There are 361 different pairs of genus-species combinations. This introduces the possible risk of class imbalance, however, there are significant observations (146611) available. Further analysis into the data distribution can highlight imbalance issues, if present.


## Task 1.3: Intermediate Dataset Selection

Based on the above I further limit my choices to the top two contenders:

1. *cancer_sample*
2. *parking_meter*

I have chosen the above due to the datasets containing a significant portion as numerical values. The parking_meter does have significant textual data such as '2 Hr' but it can easily be converted to numerical value by truncating the 'Hr'. Other textual data, such as geographical area, can be easily one hot encoded. Translating to numerical data will allow more detailed analysis and also allow wider plotting options which is focus of this exercise.

Further, both have a personal appeal to me. Cancer_sample dataset is very interesting as it provides actual medical data, which is difficult to obtain. Parking_meters data set is also very interesting given my work in regional transportation analysis.

## Task 1.4: Final Dataset Selection

In order to make the concluding dataset choice, it is important to consider the end result i.e. the associated research question. This will help gauge the project that is most appealing. Following are my research questions:

1. **cancer_sample:** Can certain attribute(s) be identified, such as mean radius, that can (binarily) classify between malignant and benign tumors?

2. **parking_meter:** Is there a general trend(s) in parking price change throughout the 24 hour period?

Finally, I select cancer_sample dataset as it's the closest to my future study area and personally the premise, being related to impacting the health sector, is  the strongest. Moreover, I have few interesting ideas on mapping and analyzing the different shape variables (dependent variables) based on my knowledge of analytic geometry.


## Task 2.1: Detailed Exploration of cancer_sample

The following four exercises help investigate the dataset into more detail - highlighting insights, data characteristics, and trends that will assist in formulating our research questions in the following section.

#### 2.1.1: Plotting distribution of numeric variable 'radius_mean'

```{r}
cancer_sample %>%
  ggplot(aes(radius_mean))+
  geom_density(aes(fill=diagnosis, alpha=0.3))
  
```





## Task 3: Research Questions

1. **Given the set of variables, can a model be generated to classify the binary response variable of malignant or benign?**

2. **Is (variable) data distribution and characteristics comparable between the benign and malignant classes?**

3. **What variables have the strongest correlations to the response variable?** Which next leads us to finding the optimized set of variables having the highest model performance. This inherently involves analyzing the three associated columns for the same parameter (example: radius_mean, radius_se, radius_worst) in order to minimize redundancy.

4. In this situation it is better to have a false positive than a false negative. Thus, we should **identify what variable leads to the highest model sensitivity**. This can also aid in incorporating noise/probabilistic modelling in the future. 